{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4cb18f-3ac8-422d-8ed8-6f273ddaf0f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "import re\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_community.tools import ArxivQueryRun, DuckDuckGoSearchRun\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d22b545-8ce5-4b50-88fb-f38cc7591ea5",
   "metadata": {},
   "source": [
    "## Papers Finder Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4872aac0-5564-404e-b1a1-b7d0ae8ac0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_finder_agent(llm):\n",
    "    \"\"\"\n",
    "    Creates a research agent equipped with Arxiv and DuckDuckGo search tools.\n",
    "\n",
    "    Args:\n",
    "        llm: An instance of a LangChain language model.\n",
    "\n",
    "    Returns:\n",
    "        An AgentExecutor ready to process research queries.\n",
    "    \"\"\"\n",
    "    # --- 2. Define the Tools ---\n",
    "    # The agent will have access to two tools:\n",
    "    # - Arxiv: For searching academic papers specifically on arxiv.org.\n",
    "    # - DuckDuckGoSearch: For general web searches to find papers on other sites\n",
    "    #   or to get a broader context.\n",
    "    arxiv_tool = ArxivQueryRun()\n",
    "    ddg_search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"arxiv_search\",\n",
    "            func=arxiv_tool.run,\n",
    "            description=\"Use this tool to search for research papers on arXiv.org. The input should be a search query.\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"web_search\",\n",
    "            func=ddg_search_tool.run,\n",
    "            description=\"Use this tool for general web searches to find research papers or articles not available on arXiv.\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # --- 3. Create the Agent's Prompt ---\n",
    "    # This prompt acts as the agent's \"brain,\" instructing it on its role,\n",
    "    # how to use its tools, and how to format its final answer.\n",
    "    # The ReAct (Reason+Act) framework is used here, which is excellent for\n",
    "    # tool-using agents.\n",
    "    prompt_template = \"\"\"\n",
    "    You are a diligent and expert research assistant. Your goal is to find relevant research papers on a given topic.\n",
    "    To answer the user's request, you must follow these steps:\n",
    "    1.  Start by using the `arxiv_search` tool to see if you can find papers on the primary repository.\n",
    "    2.  If the arXiv search is not sufficient or you need broader context, use the `web_search` tool.\n",
    "    3.  Analyze the results from your tools.\n",
    "    4.  When you have found enough information and are confident in your findings, provide a final answer.\n",
    "    5.  Your final answer should be a formatted list of the papers you found, including their titles and links.\n",
    "\n",
    "    You have access to the following tools:\n",
    "    {tools}\n",
    "\n",
    "    Use the following format for your reasoning process:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question, which should be a formatted list of papers. Each paper should be separated by a \n",
    "    unique string like 'Paper:'\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # --- 4. Create the Agent ---\n",
    "    # We use the create_react_agent function, which creates an agent that\n",
    "    # uses the ReAct framework to decide which tool to use based on the\n",
    "    # user's input and its previous actions.\n",
    "    agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "    # --- 5. Create the Agent Executor ---\n",
    "    # The AgentExecutor is the runtime for the agent. It's what actually\n",
    "    # calls the agent, executes the chosen tools, and passes the results\n",
    "    # back to the agent for the next reasoning step.\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        verbose=True,  # Set to True to see the agent's thought process\n",
    "        handle_parsing_errors=True  # Helps with robustness\n",
    "    )\n",
    "\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf700325-2b08-4368-a961-b647a8d6b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3:12b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e54a8dc7-bf0e-4b1a-a955-cfbbca1b4a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finder_agent = create_finder_agent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d663dd70-f6b3-4896-a13f-496f2870abd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic = \"multi-agent systems with orchestrators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef1f37-ba35-4376-94c9-0782759e2fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = finder_agent.invoke({\"input\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d387d525-9ef3-401d-b6ed-ad58c66e85fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Paper: Intelligent Data-Driven Architectural Features Orchestration for Network Slicing\n",
      "[https://arxiv.org/abs/2401.11799](https://arxiv.org/abs/2401.11799)\n",
      "\n",
      "Paper: Joint$\\lambda$: Orchestrating Serverless Workflows on Jointcloud FaaS Systems\n",
      "[https://arxiv.org/abs/2405.15379](https://arxiv.org/abs/2405.15379)\n",
      "\n",
      "Paper: Live Orchestral Piano, a system for real-time orchestral music generation\n",
      "[https://arxiv.org/abs/1705.05779](https://arxiv.org/abs/1705.05779)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Answer ---\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab9b9c-2042-49c3-b8e0-1ca2e47e91ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "227960dc-1280-475a-b1b2-0d1685c2a59c",
   "metadata": {},
   "source": [
    "## Summarizer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48f6813e-e5d9-4b9a-8401-582a9412d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_webpage_content(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the text content of a webpage given its URL.\n",
    "    It cleans up whitespace and truncates the content to a manageable size for the LLM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        docs = loader.load()\n",
    "        content = \" \".join([doc.page_content for doc in docs])\n",
    "        # Clean up excessive whitespace and limit length to avoid overwhelming the context window\n",
    "        cleaned_content = \" \".join(content.split())\n",
    "        max_chars = 15000\n",
    "        return cleaned_content[:max_chars]\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching content from {url}: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bd717f1-1bad-4156-ab80-cea0c6bdd364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_summarizer_agent(llm):\n",
    "    \"\"\"\n",
    "    Creates a summarization agent that can read a webpage and summarize it.\n",
    "    \"\"\"\n",
    "    web_fetch_tool = Tool(\n",
    "        name=\"web_content_fetcher\",\n",
    "        func=get_webpage_content,\n",
    "        description=\"Use this tool to fetch the text content of a webpage given its URL. The input must be a single URL.\"\n",
    "    )\n",
    "\n",
    "    tools = [web_fetch_tool]\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    You are an expert academic summarizer. Your goal is to provide a concise summary of a research paper.\n",
    "\n",
    "    You have access to the following tool:\n",
    "    {tools}\n",
    "\n",
    "    The user will provide the paper's title and a URL. Follow these steps:\n",
    "    1. Use the `web_content_fetcher` tool with the provided URL to get the paper's text content.\n",
    "    2. Read the content and create a summary that includes the main objective, methodology, and key findings of the paper.\n",
    "    3. Present the summary clearly.\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: A summary of the paper.\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    agent = create_react_agent(llm, tools, prompt)\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b25950d9-ee9d-4a4a-b44e-d48abad51060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and run the summarizer agent (imported from the new file)\n",
    "summarizer_agent = create_summarizer_agent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fe4c6-8fdd-4872-8318-75e7368a9b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for paper in response['output'].split('Paper:')[1:]:\n",
    "    \n",
    "    paper_title = paper.split('\\n')[0] \n",
    "    paper_url = paper.split('\\n')[1]\n",
    "    \n",
    "    # Format the input for the summarizer agent\n",
    "    summarizer_input = f\"Summarize the paper titled '{paper_title}' from the URL: {paper_url}\"\n",
    "\n",
    "    summary_response = summarizer_agent.invoke({\"input\": summarizer_input})\n",
    "    \n",
    "    print(summary_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c27f3b-0933-439e-83d6-7da9bb0701fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0b5491-92d7-4853-a693-2fe0dcc9b5f2",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9188424-a2a2-45a4-8efd-fdd48078eb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_orchestrator_agent(llm):\n",
    "    \"\"\"\n",
    "    Creates the master orchestrator agent that can delegate tasks to the\n",
    "    researcher and summarizer helper_agents.\n",
    "    \"\"\"\n",
    "    # 1. Instantiate the sub-helper_agents (which will become tools)\n",
    "    research_agent_executor = create_finder_agent(llm)\n",
    "    summarizer_agent_executor = create_summarizer_agent(llm)\n",
    "\n",
    "    # 2. Create tools for the orchestrator to use\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"research_paper_finder\",\n",
    "            # MODIFICATION: Wrap invoke to return only the output string\n",
    "            func=lambda query: research_agent_executor.invoke({\"input\": query})[\"output\"],\n",
    "            description=\"\"\"\n",
    "            Use this tool to find research papers on a specific academic topic.\n",
    "            The input should be a clear, concise research topic (e.g., 'quantum computing advancements').\n",
    "            This tool will return a list of relevant papers with their titles and URLs.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"paper_summarizer\",\n",
    "            # MODIFICATION: Wrap invoke to return only the output string\n",
    "            func=lambda query: summarizer_agent_executor.invoke({\"input\": query})[\"output\"],\n",
    "            description=\"\"\"\n",
    "            Use this tool to summarize a specific research paper.\n",
    "            The input must be a string containing the paper's title and its URL,\n",
    "            like this: 'Summarize the paper titled \"Paper Title\" from the URL: http://example.com/paper.pdf'\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 3. Create the prompt for the orchestrator\n",
    "    prompt_template = \"\"\"\n",
    "    You are an expert orchestrator agent. Your job is to understand a user's request and delegate tasks to specialized helper_agents.\n",
    "    You have two helper_agents at your disposal: a 'research_paper_finder' and a 'paper_summarizer'.\n",
    "\n",
    "    - If the user wants to find papers, use the `research_paper_finder`.\n",
    "    - If the user wants to summarize a paper, use the `paper_summarizer`.\n",
    "    - If the user asks for a multi-step task (e.g., find and then summarize), you must perform the steps sequentially.\n",
    "      First, call the `research_paper_finder`, then use its output to call the `paper_summarizer`.\n",
    "\n",
    "    You have access to the following tools:\n",
    "    {tools}\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do. This is your reasoning step.\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # 4. Create the orchestrator agent\n",
    "    orchestrator_agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "    # 5. Create the agent executor\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=orchestrator_agent,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee787286-59e0-4fdc-ae30-11088268f706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3:12b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1690ead9-9501-492b-b648-d22e84973475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orchestrator = create_orchestrator_agent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55bd3291-bb79-47ab-a0ab-cd6052cae7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "    First, find research papers about 'multi-agent ai systems with orchestrators'.\n",
    "    Then, take the first paper you find and summarize it.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52249d7-6657-4269-a829-906de5ef28a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = orchestrator.invoke({\"input\": task})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60a5f2-ba75-4829-a92d-eaade8c87b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Orchestrator Final Answer ---\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44edf60-f57b-4284-9ef1-ff49ae157554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
